{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 심층 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/hg-mldl/blob/master/7-2.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩에서 실행하기</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인공 신경망은 층을 많이 추가할 수 있다. 그래서 딥 러닝."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dPE5XsFhcfVD"
   },
   "source": [
    "## 2개의 층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3258,
     "status": "ok",
     "timestamp": 1600392315088,
     "user": {
      "displayName": "Haesun Park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhsWlS7sKQL-9fIkg3FmxpTMz_u-KDSs8y__P1ngQ=s64",
      "userId": "14935388527648823821"
     },
     "user_tz": -540
    },
    "id": "4sNOMcdaFVKa",
    "outputId": "f064cf9e-d3a6-4e23-90a8-f07cef6f06f3"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4435,
     "status": "ok",
     "timestamp": 1600392316271,
     "user": {
      "displayName": "Haesun Park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhsWlS7sKQL-9fIkg3FmxpTMz_u-KDSs8y__P1ngQ=s64",
      "userId": "14935388527648823821"
     },
     "user_tz": -540
    },
    "id": "aJJiRMa6FkWx"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_scaled = train_input / 255.0 # 표준화 스케일링  ->  픽셀값을 0~1 사이로\n",
    "train_scaled = train_scaled.reshape(-1, 28*28) # 784 크기의 픽셀을 1차원으로\n",
    "\n",
    "train_scaled, val_scaled, train_target, val_target = train_test_split(\n",
    "    train_scaled, train_target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4432,
     "status": "ok",
     "timestamp": 1600392316272,
     "user": {
      "displayName": "Haesun Park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhsWlS7sKQL-9fIkg3FmxpTMz_u-KDSs8y__P1ngQ=s64",
      "userId": "14935388527648823821"
     },
     "user_tz": -540
    },
    "id": "MCZWQiEwF6MD"
   },
   "outputs": [],
   "source": [
    "# 1절을 만든 신경망 모델과 다른 점은 입력층과 출력층 사이에 밀집층이 추가된 것.\n",
    "# 이 추가된 밀집층을 은닉층\n",
    "# 은닉층에는 주황색 원으로 활성화 함수가 표시되어 있다.\n",
    "# 은닉층에서 선형적인 산술계산만 수행한다면 수행 역할이 없는 셈.\n",
    "# 그래서 선형을 비 선형으로 비틀어줘야 함.\n",
    "# 은닉층은 층 사이에서 산술 계산을 도와주고, 출력층에 대한 확률을 예측하는 데 정보를 준다.\n",
    "\n",
    "dense1 = keras.layers.Dense(100, activation='sigmoid', input_shape=(784,))\n",
    "# 케라스의 첫번쨰 층은 반드시 매개변수 input_shape를 넣어주어야 한다.\n",
    "# dense1이 은닉층이고, 100개의 뉴런을 가진 밀집층. 뉴런 갯수를 정하는 데는 특별한기준x\n",
    "dense2 = keras.layers.Dense(10, activation='softmax')\n",
    "# 출력층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Agy5gCVhcrm-"
   },
   "source": [
    "## 심층 신경망 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4428,
     "status": "ok",
     "timestamp": 1600392316272,
     "user": {
      "displayName": "Haesun Park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhsWlS7sKQL-9fIkg3FmxpTMz_u-KDSs8y__P1ngQ=s64",
      "userId": "14935388527648823821"
     },
     "user_tz": -540
    },
    "id": "xmWL7kOoGB4P"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([dense1, dense2]) # 리스트로 넣어주되, 출력층을 가장 마지막에\n",
    "# 인공신경망의 강력한 성능은 이렇게 층을 추가하여 입력 데이터에 대해 연속적인 학습을\n",
    "# 진행하는 능력에서 나온다.\n",
    "# 앞에서 배운 선형 회귀, 로지스틱 회귀, 결정 트리 등 다른 머신러닝 알고리즘들과는 대조.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4425,
     "status": "ok",
     "timestamp": 1600392316272,
     "user": {
      "displayName": "Haesun Park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhsWlS7sKQL-9fIkg3FmxpTMz_u-KDSs8y__P1ngQ=s64",
      "userId": "14935388527648823821"
     },
     "user_tz": -540
    },
    "id": "em0xDl8qa12J",
    "outputId": "1e28b7a3-29c3-4640-a587-f45cb14a0339",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() # 층에 대한 유용한 정보\n",
    "\n",
    "# 출력크기는 왜 None? 샘플 갯수가 아직 정해져있ㅎ지 않아서\n",
    "# 케라스 모델의 fit메서드에 훈련 데이터를 주입하면 데이터들을 한번에 사용하지 않고\n",
    "# 나누어 여러번에 걸쳐 경사하강법 단계를 수행하기 떄문., = 미니 배치 경사하강법\n",
    "# 어떤 batch size로도 유연하게 대응할 수 있도록 none으로 결정.\n",
    "\n",
    "# 100은 뉴런의 갯수고, 100개의 출력이 나올 것.\n",
    "# 샘플마다 784개의 픽셀값이 은닉층을 통과하면서 100개의 특성으로 압축되었다.\n",
    "# 마지막으로 모델파라미터 개수 : 입력 픽셀 784개 x 100개의 모든 조합에 대한 가중치\n",
    "    # 입력층에 784개의 뉴런 , 출력층에 100개의 뉴런.  + 뉴런마다 1개의 절편도 있다.\n",
    "        # = 78500\n",
    "        \n",
    "    # 출력층에서는 은닉층을 통과한 100개로 압축된 특성이자 뉴런과 10개의 뉴런의 조합\n",
    "        # 으로 모두 연결되고(+활성화 함수 존재.) + 뉴런마다 1개 절편\n",
    "            # 1000+10 = 1010 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.8066\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.4108 - accuracy: 0.8517\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3746 - accuracy: 0.8649\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3521 - accuracy: 0.8730\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3348 - accuracy: 0.8791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22a289b3ca0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "\n",
    "model.fit(train_scaled, train_target, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qAi41rBTdk7k"
   },
   "source": [
    "## 층을 추가하는 다른 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4421,
     "status": "ok",
     "timestamp": 1600392316273,
     "user": {
      "displayName": "Haesun Park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhsWlS7sKQL-9fIkg3FmxpTMz_u-KDSs8y__P1ngQ=s64",
      "userId": "14935388527648823821"
     },
     "user_tz": -540
    },
    "id": "0XeV6V4ha3I8"
   },
   "outputs": [],
   "source": [
    "# 시퀀셜 클래스에 층을 추가하는 방법.\n",
    "model = keras.Sequential([ # 층을 한 눈에 쉽게 알아볼 수 있는 방법\n",
    "    keras.layers.Dense(100, activation='sigmoid', input_shape=(784,), name='hidden'),\n",
    "    keras.layers.Dense(10, activation='softmax', name='output') # 층마다 name을 붙여줄 수 있다.\n",
    "], name='패션 MNIST 모델') # 모델도 이름 붙여줄 수 있네 다른 것과 구별하기 위해서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4417,
     "status": "ok",
     "timestamp": 1600392316273,
     "user": {
      "displayName": "Haesun Park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhsWlS7sKQL-9fIkg3FmxpTMz_u-KDSs8y__P1ngQ=s64",
      "userId": "14935388527648823821"
     },
     "user_tz": -540
    },
    "id": "bwXDLSOWbm3L",
    "outputId": "86845921-adac-4f1b-b119-e3d06560f922"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"패션 MNIST 모델\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden (Dense)              (None, 100)               78500     \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Playdata\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Playdata\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Playdata\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Playdata\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\Playdata\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Playdata\\anaconda3\\lib\\contextlib.py\", line 492, in enter_context\n        result = _cm_type.__enter__(cm)\n    File \"C:\\Users\\Playdata\\anaconda3\\lib\\contextlib.py\", line 135, in __enter__\n        return next(self.gen)\n\n    ValueError: '패션 MNIST 모델/' is not a valid root scope name. A root scope name has to match the following pattern: ^[A-Za-z0-9.][A-Za-z0-9_.\\\\/>-]*$\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filetu709xap.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\contextlib.py:492\u001b[0m, in \u001b[0;36m_BaseExitStack.enter_context\u001b[1;34m(self, cm)\u001b[0m\n\u001b[0;32m    490\u001b[0m _cm_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(cm)\n\u001b[0;32m    491\u001b[0m _exit \u001b[38;5;241m=\u001b[39m _cm_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__exit__\u001b[39m\n\u001b[1;32m--> 492\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43m_cm_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__enter__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_push_cm_exit(cm, _exit)\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Playdata\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Playdata\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Playdata\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Playdata\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\Playdata\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Playdata\\anaconda3\\lib\\contextlib.py\", line 492, in enter_context\n        result = _cm_type.__enter__(cm)\n    File \"C:\\Users\\Playdata\\anaconda3\\lib\\contextlib.py\", line 135, in __enter__\n        return next(self.gen)\n\n    ValueError: '패션 MNIST 모델/' is not a valid root scope name. A root scope name has to match the following pattern: ^[A-Za-z0-9.][A-Za-z0-9_.\\\\/>-]*$\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "\n",
    "model.fit(train_scaled, train_target, epochs=5)\n",
    "\n",
    "# 얘는 왜 안되지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4694,
     "status": "ok",
     "timestamp": 1600392316555,
     "user": {
      "displayName": "Haesun Park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhsWlS7sKQL-9fIkg3FmxpTMz_u-KDSs8y__P1ngQ=s64",
      "userId": "14935388527648823821"
     },
     "user_tz": -540
    },
    "id": "yZSAxgZCbax7"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# 또 층을 추가하는 방법\n",
    "model.add(keras.layers.Dense(100, activation='sigmoid', input_shape=(784,)))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4689,
     "status": "ok",
     "timestamp": 1600392316555,
     "user": {
      "displayName": "Haesun Park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhsWlS7sKQL-9fIkg3FmxpTMz_u-KDSs8y__P1ngQ=s64",
      "userId": "14935388527648823821"
     },
     "user_tz": -540
    },
    "id": "bW2coaNQboe5",
    "outputId": "3f5430b2-fe8f-4576-8d17-1ce9a8084b0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20567,
     "status": "ok",
     "timestamp": 1600392332438,
     "user": {
      "displayName": "Haesun Park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhsWlS7sKQL-9fIkg3FmxpTMz_u-KDSs8y__P1ngQ=s64",
      "userId": "14935388527648823821"
     },
     "user_tz": -540
    },
    "id": "kkYrPJembpYk",
    "outputId": "7f7f5eb5-0496-45af-a10b-d58600a00545"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5623 - accuracy: 0.8081\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.4084 - accuracy: 0.8525\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3744 - accuracy: 0.8652\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3518 - accuracy: 0.8725\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3353 - accuracy: 0.8786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22a3b235180>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "\n",
    "model.fit(train_scaled, train_target, epochs=5)\n",
    "# 추가된 층이 성능을 향상시켰다는 걸 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_dfXJDhwcyAK"
   },
   "source": [
    "## 렐루 활성화 함수\n",
    ": 초창기 인공 신경망의 은닉층에 많이 사용된 함수는 시그모이드.\n",
    "하지만 함수의 오른쪽, 왼쪽 끝으로 갈수록 그래프가 누워있어서 올바른 출력을 만드는데\n",
    "신속하게 대응X\n",
    "특히 층이 많은 심층신경망일수록 그 효과가 누적되어 학습 더어려워짐.\n",
    "\n",
    "이를 개선하기위한 활성화 함수가 렐루\n",
    "렐루는 입력이 양수일 경우 마치 활성화 함수가 없는거서첢 그냥 입력을 통과.\n",
    "음수일 경우에는 0\n",
    "\n",
    "렐루함수는 max(0,z)와 같이 쓸 수 있고, z가 0보다 크면 z를 출력, z가 0보다 작으면 0을 출력한다.\n",
    "렐루는 특히 이미지 처리에서 좋은 성능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20562,
     "status": "ok",
     "timestamp": 1600392332438,
     "user": {
      "displayName": "Haesun Park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhsWlS7sKQL-9fIkg3FmxpTMz_u-KDSs8y__P1ngQ=s64",
      "userId": "14935388527648823821"
     },
     "user_tz": -540
    },
    "id": "dG7yF8g6b062"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential() \n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28))) # 2828크기라서 인공신경망에\n",
    "# 주입하기 위해 넘파이 배열의 reshape메서드를 사용해 1차원으로 펼쳐왓었는데\n",
    "#케라스에서는 플래튼 층을 제공한다.\n",
    "# flatten 클래스는 배치차원을 제외하고 나머지 입력 차원을 모두 일렬로 펼치는 역할만 한다.\n",
    "# 입력에 곱해지는 가중치나 절편이 없다. 따라서 인공 신경망의 성능을 위해\n",
    "# 기여하는 바는 없다., 입력층과 은닉층 사이에 있으니 이를층이라 부른다.\n",
    "\n",
    "# 플래툰 클래스는 학습하는 층도 아니야.\n",
    "# 모델 파라미터 개수 : 0 \n",
    "\n",
    "# 케라스의 플래툰 층을 신경망 모델에 추가하면 입력값의 차원을 짐작할 수 있다는 것이 \n",
    "# 또 하나의 장점 : 앞의 출력에서 784개의 입력이 첫번째 은닉층에 전달된다는 것을 알 수 있다.\n",
    "# 이는 이전에 만들었던 모델에서는 쉽게 눈치채기 어려웠던 것.\n",
    "\n",
    "# 입력 데이터에 대한 전처리 과정을 가능한 모델에 포함시키는 것이 케라스 API의 철학 중 하나.\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 259
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20560,
     "status": "ok",
     "timestamp": 1600392332438,
     "user": {
      "displayName": "Haesun Park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhsWlS7sKQL-9fIkg3FmxpTMz_u-KDSs8y__P1ngQ=s64",
      "userId": "14935388527648823821"
     },
     "user_tz": -540
    },
    "id": "zHogWhu6g90a",
    "outputId": "9b75dae0-14ef-47ad-8c73-f12f3b3c962c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21416,
     "status": "ok",
     "timestamp": 1600392333301,
     "user": {
      "displayName": "Haesun Park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhsWlS7sKQL-9fIkg3FmxpTMz_u-KDSs8y__P1ngQ=s64",
      "userId": "14935388527648823821"
     },
     "user_tz": -540
    },
    "id": "JfPe_ruQdhqA"
   },
   "outputs": [],
   "source": [
    "(train_input, train_target), (test_input, test_target) =\\\n",
    "keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "train_scaled = train_input / 255.0\n",
    "\n",
    "train_scaled, val_scaled, train_target, val_target = train_test_split(\n",
    "    train_scaled, train_target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36228,
     "status": "ok",
     "timestamp": 1600392348116,
     "user": {
      "displayName": "Haesun Park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhsWlS7sKQL-9fIkg3FmxpTMz_u-KDSs8y__P1ngQ=s64",
      "userId": "14935388527648823821"
     },
     "user_tz": -540
    },
    "id": "9PGejuuhdvvk",
    "outputId": "ffeaf6d5-90ca-4eee-bfab-45dab139a332"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5309 - accuracy: 0.8138\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3954 - accuracy: 0.8588\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3580 - accuracy: 0.8715\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3354 - accuracy: 0.8801\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3210 - accuracy: 0.8861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22a3b763580>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "# 확실히 시그모이드 함수보다 relu함수가 성능이 좋다.\n",
    "model.fit(train_scaled, train_target, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36721,
     "status": "ok",
     "timestamp": 1600392348614,
     "user": {
      "displayName": "Haesun Park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhsWlS7sKQL-9fIkg3FmxpTMz_u-KDSs8y__P1ngQ=s64",
      "userId": "14935388527648823821"
     },
     "user_tz": -540
    },
    "id": "lVYLpnjeep4y",
    "outputId": "629d613d-1a2e-4053-9a6d-0e8c80b3edec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 1ms/step - loss: 0.3576 - accuracy: 0.8792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3576281666755676, 0.8792499899864197]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_scaled, val_target) \n",
    "# 검증 세트에서의 성능은 1절의 은닉층을 추가하지 않은 경우보다 몇퍼센트 성능이 향상."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3YtLsmGAoavz"
   },
   "source": [
    "## 옵티마이저\n",
    ": 하이퍼 파라미터는 신경망에 특히 많다.\n",
    "은닉층의 개수, 뉴런 개수, 활성화 함수, 층의 종류, 배치 사이즈 매개변수, 에포크 매개변수 등\n",
    "\n",
    "추가할 은닉층의 개수는 모델이 학습하는 것이 아니라 우리가 지정해주어야 할 하이퍼파라미터.\n",
    "\n",
    "은닉층의 뉴런 개수 조차 하이퍼 파라미터.\n",
    "\n",
    "이 장에서는 가장 기본적인 밀집층만 다루지만, 다른 종류의 층을 선택할 수도 있다.\n",
    "\n",
    "케라스는 기본적으로 미니배치 경사 하강법을 사용하여 미니배치 개수 32개다.\n",
    "fit()메서드의 batch_size 매개변수에서 이를 조정할 수 있으며 이 역시 하이퍼파라미터.\n",
    "\n",
    "\n",
    "조정해야 할 하이퍼 파라미터가 정말 많다.\n",
    "처음부터 모델을 구성하고, 각종 하이퍼 파라미터 최적값을 찾는 것은 어려운 작업.\n",
    "여러가지 옵티마이저를 테스트.\n",
    "\n",
    "\n",
    "마지막 compile 메소드에서는 케라스의 기본 경사 하강법 알고리즘인\n",
    "RMSprop를 사용할건데, 케라스는 '다양한 종류의 경사 하강법 알고리즘'을 제공.\n",
    "이들을 옵티마이저 라고 한다.\n",
    " \n",
    "RMSprop의 학습률 또한 조정할 하이퍼 파라미터 중 하나.\n",
    "\n",
    "가장 기본적인 옵티마이저는 확률적 경사 하강법인 SGD다.\n",
    "이름이 SGD이지만 1개의 샘플을 뽑아서 훈련하지 않고 앞서 언급한 것처럼 기본적으로\n",
    "미니 배치를 사용\n",
    "\n",
    "SGD 옵티마이저를 사용하려면 complie 메서드의 optimizer 매개변수를 sgd로 저장.\n",
    "\n",
    "이 옵티마이저는 tensorflow.keras.optimizer 패키지 아래 sgd 클래스로 구현되어 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NxVj04Haocwa"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy'\n",
    "              , metrics='accuracy')\n",
    "# sgd 문자열은 이 클래스의 기본 설정 매개변수로 생성한 객체와 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1426O4G8Hpfi"
   },
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD()\n",
    "# sgd 문자열은 이 클래스의 기본 설정 매개변수로 생성한 객체와 동일.\n",
    "model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy'\n",
    "              , metrics='accuracy')\n",
    "\n",
    "# 즉 바로 위의 코드와 100% 일치."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sh-HDiULlp18"
   },
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD(learning_rate=0.1)\n",
    "# 만약 SGD 클래스의 학습률 기본값이 0.01일 때 이를 바꾸고 싶다면 다음과 같이\n",
    "# 원하는 학습률을 learning_rate 매개변수에 지정하여 사용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uF1XolBXsl3a"
   },
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD(momentum=0.9, nesterov=True)\n",
    "# 기본 경사 하강법 옵티마이저는 모두 SGD 클래스에서 제공.\n",
    "# SGD 클래스의 모멘텀 매개변수의 기본값 = 0\n",
    "# 이를 0보다 큰 값으로 지정하면 마치 이전의 그레이디언트를 가속도처럼 사용하는\n",
    "# 모멘텀 최적화를 사용합니다. 보통 모멘텀 매개변수는 0.9이상을 지정.\n",
    "\n",
    "# 모멘텀을 대신하여 SGD를 사용하여 신경망 학습 가능.\n",
    "# 그럼에도 불구하고 모멘텀 사용 이유 : 손실된 값들이 발생하거나\n",
    "# 로컬 최솟값에 빠지는 부분 방지할 수 있기 때문.\n",
    "# 모멘텀은 이러한 다소 극단적인 그래프 결과가 산출되지 않도록 부드럽게 결과를 산출해주는 역할을 수행\n",
    "\n",
    "# SGD 클래스의 nesterov 매개변수를 기본값 False에서 True로 바꾸면\n",
    "# 네스테로프 모멘텀 최적화를 사용한다.\n",
    "# 네스테로프 모멘텀은 모멘텀 최적화를 2번 반복 구현. 대부분의 경우 네모 최적화가\n",
    "# 기본 확률적 경사 하강법보다 더 나은 성능.\n",
    "\n",
    "# 학습률 : 머신러닝에서 학습되는 양 또는 단계.\n",
    "# 모델이 최적점에 가까이 갈수록 학습률을 낮출 수 있다. => 안정적으로 최적점에 수렴할 가능성\n",
    "# 이런 학습률을 적응적 학습률 - 이런 방식들은 학습률 매개변수를 튜닝하는 수고를 덜 수 O\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hy2MENbL170j"
   },
   "outputs": [],
   "source": [
    "# 적응적 학습률을 사용하는 대표적 옵티는 Adagrad와 RMSprop이다.\n",
    "# 각각 compile 메서드의 옵티마이저 메개변수에 adagrad, RMSprop으로 지정할 수 있다.\n",
    "adagrad = keras.optimizers.Adagrad()\n",
    "model.compile(optimizer=adagrad, loss='sparse_categorical_crossentropy'\n",
    "              , metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KkpbSMXWtakr"
   },
   "outputs": [],
   "source": [
    "rmsprop = keras.optimizers.RMSprop()\n",
    "model.compile(optimizer=rmsprop, loss='sparse_categorical_crossentropy'\n",
    "              , metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 886,
     "status": "ok",
     "timestamp": 1600420988092,
     "user": {
      "displayName": "Haesun Park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhsWlS7sKQL-9fIkg3FmxpTMz_u-KDSs8y__P1ngQ=s64",
      "userId": "14935388527648823821"
     },
     "user_tz": -540
    },
    "id": "Gdu0hQIAz4JW"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12812,
     "status": "ok",
     "timestamp": 1600392383901,
     "user": {
      "displayName": "Haesun Park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhsWlS7sKQL-9fIkg3FmxpTMz_u-KDSs8y__P1ngQ=s64",
      "userId": "14935388527648823821"
     },
     "user_tz": -540
    },
    "id": "2tcxIfILoi1t",
    "outputId": "32c299a0-85ba-4adc-d1d4-aa8caa21e91b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.5266 - accuracy: 0.8148\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3919 - accuracy: 0.8585\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3495 - accuracy: 0.8730\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3236 - accuracy: 0.8813\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3046 - accuracy: 0.8884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fef38bfc080>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy'\n",
    "              , metrics='accuracy')\n",
    "\n",
    "# 모멘텀 최적화와 RMSprop의 장점을 접목한 것이 Adam이다.\n",
    "# Adam은 RMSprop과 함께 맨 처음 시도해 볼 수 있는 좋은 알고리즘.\n",
    "# 적응적 학습률을 사용하는 3개의 클래스는 학습률 매개변수의 기본값으로 모두 0.001을 사용.\n",
    "\n",
    "# compile()메서드의 옵티마이저를 adam으로 설정하고 5번 에포크 훈련\n",
    "# 출력 결과를 보면 RMSprop 사용햇을 때와 거의 같은 성능.\n",
    "model.fit(train_scaled, train_target, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1058,
     "status": "ok",
     "timestamp": 1600407984847,
     "user": {
      "displayName": "Haesun Park",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhsWlS7sKQL-9fIkg3FmxpTMz_u-KDSs8y__P1ngQ=s64",
      "userId": "14935388527648823821"
     },
     "user_tz": -540
    },
    "id": "8gxAWehsv9Gi",
    "outputId": "cdc6c3a3-323c-4f93-e7db-bf2d6bc73a00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 0s 1ms/step - loss: 0.3544 - accuracy: 0.8730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35439205169677734, 0.8730000257492065]"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_scaled, val_target)\n",
    "# 검증세트에서는 기본 RMSprop보다 조금 나은 성능 보여줌."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 장에서 여러 개의 층을 추가하여 다층 인공 신경망(심층신경망)을 만드는 방법 터득.\n",
    "또 케라스 API를 사용하여 층을 추가하는 여러가지 방법\n",
    "\n",
    "케라스 모델의 정보를 요약해주는 summary() 메서드\n",
    "\n",
    "출력값의 의미를 이해하고 모델 파라미터 개수를 계산해 맞추어도 보고,\n",
    "모델 파라미터 개수를 계산하는 과정은 모델을 올바르게 이해하고 있는지 확인하는 좋은 방법\n",
    "\n",
    "은닉층에 적용한 시그모이드 활성화 함수 대신에 새로운 렐루 활성화 함수에 대해 배웠고,\n",
    "이를 적용해 약간의 성능향상.\n",
    "\n",
    "또한 다양한 고급 경사 하강법 옵티들을 적용하는 방법도 살펴봄.\n",
    "\n",
    "케라스API를 사용하면 이런 작업이 어렵지 않고 직관적으로 구성할 수 있다."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPFR5xmwdAy7v5dDzeufZd4",
   "collapsed_sections": [],
   "name": "7-2 심층 신경망.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
